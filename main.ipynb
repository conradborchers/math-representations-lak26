{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1244ca1b-8916-4843-87ca-97ecf1d7e8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7de2da-4c47-4bd3-8553-739a1a719371",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../../embedded_output.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f18edc3-dc7b-42b1-bcd3-a223498054a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d218933a-6704-4650-b61f-675ced24a9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['skill_code']).copy()\n",
    "\n",
    "df = df[df['correctness'] <= 1].copy()\n",
    "df = df[df['correctness'] >= 0].copy()\n",
    "\n",
    "mask = df.answer_text.str.contains(r\"[A-Za-z]\", na=False)\n",
    "df = df[mask].copy() # must include a letter\n",
    "\n",
    "print('after removing non letter')\n",
    "print(df.shape)\n",
    "\n",
    "mask.value_counts()\n",
    "\n",
    "mask_words = df.answer_text.str.split().str.len() >= 10\n",
    "df = df[mask_words].copy()\n",
    "\n",
    "print('after removing non 10 words')\n",
    "print(df.shape)\n",
    "\n",
    "mask_words.value_counts()\n",
    "\n",
    "s = df.groupby('teacher_id')['correctness'].std()\n",
    "df = df[df['teacher_id'].isin(s[s.notna() & (s != 0)].index)]\n",
    "\n",
    "print('after removing teachers with no grading variance')\n",
    "print(df.shape)\n",
    "\n",
    "df.shape\n",
    "\n",
    "import re\n",
    "mask_img = ~df.answer_text.str.fullmatch(r\"\\s*(<p>\\s*)?<img[^>]*>\\s*(</p>\\s*)?\", flags=re.I)\n",
    "df = df[mask_img].copy()\n",
    "\n",
    "print('after removing images')\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194aae67-bf2d-424b-8d6f-9b37260cc22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(df.teacher_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5443ad6-7583-4f9b-9806-4f2ce11dfb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(df.student_user_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ac7b0b-fdc3-4702-b98c-ebfd266efd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.metrics import r2_score, mean_squared_error, roc_auc_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "df_sorted=df.sort_values(\"problem_start_time\").reset_index(drop=True)\n",
    "g_t=df_sorted.groupby(\"teacher_id\")[\"correctness\"]\n",
    "df_sorted[\"teacher_prior\"]=((g_t.cumsum()-df_sorted[\"correctness\"])/g_t.cumcount().replace(0,np.nan)).fillna(0)\n",
    "\n",
    "cut=int(len(df_sorted)*0.8)\n",
    "train,test=df_sorted.iloc[:cut],df_sorted.iloc[cut:]\n",
    "\n",
    "resp_tr,prob_tr=np.vstack(train.embedding_response),np.vstack(train.embedding_problembody)\n",
    "resp_te,prob_te=np.vstack(test.embedding_response),np.vstack(test.embedding_problembody)\n",
    "ytr,yte=train.correctness.values,test.correctness.values\n",
    "median_val=df_sorted.correctness.median()\n",
    "\n",
    "tp_tr,tp_te=train.teacher_prior.values.reshape(-1,1),test.teacher_prior.values.reshape(-1,1)\n",
    "\n",
    "centroids=pd.DataFrame(resp_tr).groupby(train.problem_body).mean()\n",
    "cent_tr=centroids.reindex(train.problem_body).values\n",
    "cent_te=centroids.reindex(test.problem_body).fillna(0).values\n",
    "\n",
    "def run(name,Xtr,Xte):\n",
    "    m=LassoCV(alphas=np.logspace(-3,0,10),cv=3,max_iter=5000,n_jobs=-1,precompute=False).fit(Xtr,ytr)\n",
    "    p=np.clip(m.predict(Xte),0,1)\n",
    "    return dict(model=name,alpha=m.alpha_,p=p)\n",
    "\n",
    "variants=[\n",
    "    (\"teacher_prior_only\",tp_tr,tp_te),\n",
    "    (\"resp_only\",resp_tr,resp_te),\n",
    "    (\"problem_only\",prob_tr,prob_te),\n",
    "    (\"problem+response\",np.hstack([prob_tr,resp_tr]),np.hstack([prob_te,resp_te])),\n",
    "    (\"resp_minus_prob\",resp_tr-prob_tr,resp_te-prob_te),\n",
    "    (\"resp_minus_respCentroidByProblem\",resp_tr-cent_tr,resp_te-cent_te),\n",
    "    (\"teacher_prior+resp\",np.hstack([tp_tr,resp_tr]),np.hstack([tp_te,resp_te])),\n",
    "    (\"teacher_prior+resp_minus_prob\",np.hstack([tp_tr,resp_tr-prob_tr]),np.hstack([tp_te,resp_te-prob_te])),\n",
    "    (\"teacher_prior+resp_minus_respCentroidByProblem\",np.hstack([tp_tr,resp_tr-cent_tr]),np.hstack([tp_te,resp_te-cent_te])),\n",
    "]\n",
    "\n",
    "res=[run(n,Xtr,Xte) for n,Xtr,Xte in tqdm(variants)]\n",
    "bin_y=(yte>=median_val).astype(int)\n",
    "idx=np.random.randint(0,len(yte),(1000,len(yte)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff3e4cd-eee6-46e9-84aa-470b507c62ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows=[]\n",
    "for r in tqdm(res):\n",
    "    p=r[\"p\"]\n",
    "    r2=r2_score(yte,p); mse=mean_squared_error(yte,p)\n",
    "    try: auc=roc_auc_score(bin_y,p)\n",
    "    except: auc=np.nan\n",
    "    r2_b=np.array([r2_score(yte[i],p[i]) for i in idx])\n",
    "    mse_b=np.array([mean_squared_error(yte[i],p[i]) for i in idx])\n",
    "    auc_b=[]\n",
    "    for i in idx:\n",
    "        try: auc_b.append(roc_auc_score(bin_y[i],p[i]))\n",
    "        except: pass\n",
    "    auc_b=np.array(auc_b) if len(auc_b)>0 else np.array([np.nan])\n",
    "    rows.append(dict(model=r[\"model\"],alpha=r[\"alpha\"],\n",
    "                     r2=r2,r2_lo=np.percentile(r2_b,2.5),r2_hi=np.percentile(r2_b,97.5),\n",
    "                     mse=mse,mse_lo=np.percentile(mse_b,2.5),mse_hi=np.percentile(mse_b,97.5),\n",
    "                     auc=auc,auc_lo=np.nanpercentile(auc_b,2.5),auc_hi=np.nanpercentile(auc_b,97.5)))\n",
    "df_ci=pd.DataFrame(rows).sort_values(\"model\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b11ccd8-8627-4773-9023-bbeb03be73ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.DataFrame(df_ci).sort_values(\"auc\",ascending=False).drop(columns=['r2', 'alpha', 'r2_lo', 'r2_hi']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adb21a1-4ffa-444c-839a-c4c1b9f15d79",
   "metadata": {},
   "source": [
    "## Export for manual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3af8584-d887-458e-a8c8-c96907ee7cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "\n",
    "names=[\"teacher_prior+resp\",\"resp_only\",\"teacher_prior_only\"]\n",
    "preds={r[\"model\"]:r[\"p\"] for r in res if r[\"model\"] in names}\n",
    "\n",
    "Z=pd.DataFrame({\n",
    "    \"row_idx\":np.arange(len(yte)),\n",
    "    \"teacher_id\":test[\"teacher_id\"].to_numpy(),\n",
    "    \"problem_id\":test[\"problem_body\"].to_numpy(),\n",
    "    \"answer_text\":test[\"answer_text\"].to_numpy(),\n",
    "    \"correctness\":yte,\n",
    "    \"timestamp\":test[\"problem_start_time\"].to_numpy(),\n",
    "    \"pred_tp_plus_resp\":preds[\"teacher_prior+resp\"],\n",
    "    \"pred_resp_only\":preds[\"resp_only\"],\n",
    "    \"pred_tp_only\":preds[\"teacher_prior_only\"],\n",
    "})\n",
    "\n",
    "P=np.vstack([\n",
    "    Z[\"pred_tp_plus_resp\"].values,\n",
    "    Z[\"pred_resp_only\"].values,\n",
    "    Z[\"pred_tp_only\"].values\n",
    "]).T\n",
    "\n",
    "cands=np.linspace(0,1,101)\n",
    "disagree=lambda B: (B.max(axis=1)!=B.min(axis=1)).sum()\n",
    "thr=cands[int(np.argmax([disagree((P>=t).astype(int)) for t in cands]))]\n",
    "\n",
    "Z[\"bin_tp_plus_resp\"]=(Z[\"pred_tp_plus_resp\"]>=thr).astype(int)\n",
    "Z[\"bin_resp_only\"]=(Z[\"pred_resp_only\"]>=thr).astype(int)\n",
    "Z[\"bin_tp_only\"]=(Z[\"pred_tp_only\"]>=thr).astype(int)\n",
    "\n",
    "Z=Z[Z[[\"bin_tp_plus_resp\",\"bin_resp_only\",\"bin_tp_only\"]].nunique(axis=1)>1].reset_index(drop=True)\n",
    "\n",
    "Z[\"binary_preds_pattern\"]=Z[[\"bin_tp_plus_resp\",\"bin_resp_only\",\"bin_tp_only\"]].astype(str).agg(\"-\".join,axis=1)\n",
    "Z[\"binary_preds_pattern_readable\"]=(\n",
    "    \"TP+Resp=\"+Z[\"bin_tp_plus_resp\"].astype(str)+\n",
    "    \" | Resp-only=\"+Z[\"bin_resp_only\"].astype(str)+\n",
    "    \" | TP-only=\"+Z[\"bin_tp_only\"].astype(str)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076db1d0-05c0-461f-9f76-685507dfbfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "E_df = pd.DataFrame(resp_te[Z[\"row_idx\"].to_numpy()])\n",
    "E_df[\"binary_preds_pattern\"] = Z[\"binary_preds_pattern\"].to_numpy()\n",
    "centroids = E_df.groupby(\"binary_preds_pattern\").mean(numeric_only=True)\n",
    "Z[\"prototype_score\"] = cosine_similarity(\n",
    "    E_df.drop(columns=\"binary_preds_pattern\").values,\n",
    "    centroids.loc[Z[\"binary_preds_pattern\"]].values\n",
    ")[:,0]\n",
    "\n",
    "Z = Z.drop_duplicates(subset=[\"answer_text\"]).reset_index(drop=True)\n",
    "\n",
    "m = Z[\"binary_preds_pattern\"].nunique()\n",
    "k_high = 150 // m\n",
    "k_low = 150 // m\n",
    "\n",
    "grp = Z.groupby(\"binary_preds_pattern\", group_keys=False)\n",
    "S_high = grp.apply(lambda g: g.nlargest(k_high, \"prototype_score\"))\n",
    "S_low = grp.apply(lambda g: g.nsmallest(k_low, \"prototype_score\"))\n",
    "\n",
    "rem_high = 150 - len(S_high)\n",
    "rem_low = 150 - len(S_low)\n",
    "pool = Z.drop(S_high.index.union(S_low.index), errors=\"ignore\")\n",
    "S_high = pd.concat([S_high, pool.nlargest(rem_high, \"prototype_score\")]) if rem_high > 0 else S_high\n",
    "pool = pool.drop(S_high.index, errors=\"ignore\")\n",
    "S_low = pd.concat([S_low, pool.nsmallest(rem_low, \"prototype_score\")]) if rem_low > 0 else S_low\n",
    "\n",
    "S = pd.concat([S_high, S_low]).drop_duplicates(subset=[\"answer_text\"]).head(300)\n",
    "\n",
    "S = S[[\n",
    "    \"row_idx\",\"teacher_id\",\"problem_id\",\"timestamp\",\"answer_text\",\"correctness\",\n",
    "    \"pred_tp_plus_resp\",\"pred_resp_only\",\"pred_tp_only\",\n",
    "    \"bin_tp_plus_resp\",\"bin_resp_only\",\"bin_tp_only\",\n",
    "    \"binary_preds_pattern\",\"binary_preds_pattern_readable\",\"prototype_score\"\n",
    "]].copy()\n",
    "\n",
    "for col in [\"theme_reason_for_difference\",\"theme_strategy_pattern\",\"theme_student_factor\",\"theme_teacher_factor\",\"coder_notes\"]:\n",
    "    S[col] = \"\"\n",
    "\n",
    "S.to_csv(\"lak26-representations-coding_sample.csv\", index=False)\n",
    "S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb909f60-4b3d-48f3-ac3f-e467f54cd45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z.binary_preds_pattern.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34546c3-d67e-4dff-ad77-3197ef1372fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "S.binary_preds_pattern.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9343cfaf-100f-4c0f-be62-d8a0a43ab30b",
   "metadata": {},
   "source": [
    "## Interpretability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d01ccf-9649-4549-aaf8-7d75a3b3e349",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "m_resp=LassoCV(alphas=np.logspace(-3,0,10),cv=3,max_iter=5000,n_jobs=-1,precompute=False).fit(resp_tr,ytr)\n",
    "m_tonly=LassoCV(alphas=np.logspace(-3,0,10),cv=3,max_iter=5000,n_jobs=-1,precompute=False).fit(tp_tr,ytr)\n",
    "Xtr=np.hstack([tp_tr,resp_tr]); Xte=np.hstack([tp_te,resp_te])\n",
    "m_adj=LassoCV(alphas=np.logspace(-3,0,10),cv=3,max_iter=5000,n_jobs=-1,precompute=False).fit(Xtr,ytr)\n",
    "\n",
    "def resp_coefs(model):\n",
    "    c=model.coef_\n",
    "    return c if c.size==resp_tr.shape[1] else c[-resp_tr.shape[1]:]\n",
    "\n",
    "def summarize(mode, coefs):\n",
    "    nz=np.flatnonzero(coefs); k=len(nz); pct=100*k/len(coefs)\n",
    "    print(f\"[{mode}] non-zero: {k}/{len(coefs)} ({pct:.1f}%)\")\n",
    "    if k:\n",
    "        top=np.argsort(np.abs(coefs[nz]))[::-1][:100]\n",
    "        idx=nz[top]; w=coefs[idx]\n",
    "        print(f\"[{mode}] top dims (idx,wt):\"); [print(f\"{int(i):4d}\\t{wj:+.6f}\") for i,wj in zip(idx,w)]\n",
    "    return nz\n",
    "\n",
    "def proj_and_resid_unadjusted():\n",
    "    c=resp_coefs(m_resp); nz=summarize(\"unadjusted\",c)\n",
    "    proj=resp_te[:,nz]@c[nz]\n",
    "    resid=yte-m_resp.predict(resp_te)\n",
    "    return proj,resid,c,nz\n",
    "\n",
    "def proj_and_resid_adjusted():\n",
    "    c=resp_coefs(m_adj); nz=summarize(\"adjusted\",c)\n",
    "    proj=resp_te[:,nz]@c[nz]\n",
    "    resid=yte-m_tonly.predict(tp_te)\n",
    "    return proj,resid,c,nz\n",
    "\n",
    "proj_u,resid_u,c_u,nz_u=proj_and_resid_unadjusted()\n",
    "proj_a,resid_a,c_a,nz_a=proj_and_resid_adjusted()\n",
    "\n",
    "n=len(yte)\n",
    "idx=np.random.choice(n,n,replace=False)\n",
    "sns.kdeplot(x=proj_u[idx],y=resid_u[idx],fill=True,cmap=\"viridis\"); plt.xlabel(\"Projection (resp-only coefs)\"); plt.ylabel(\"Residual (resp-only)\"); plt.title(\"Embedding signals (unadjusted)\"); plt.savefig(\"embedding_signals_unadjusted.pdf\",format=\"pdf\",bbox_inches=\"tight\"); plt.show()\n",
    "sns.kdeplot(x=proj_a[idx],y=resid_a[idx],fill=True,cmap=\"viridis\"); plt.xlabel(\"Projection (teacher+resp coefs)\"); plt.ylabel(\"Residual (teacher-only)\"); plt.title(\"Embedding signals (adjusted)\"); plt.savefig(\"embedding_signals_adjusted.pdf\",format=\"pdf\",bbox_inches=\"tight\"); plt.show()\n",
    "\n",
    "def show_dim(mode=\"adjusted\",rank=0,k=3):\n",
    "    if mode==\"adjusted\":\n",
    "        coefs=c_a; nz=nz_a; dim=nz[np.argsort(np.abs(coefs[nz]))[::-1][rank]]\n",
    "        proj=resp_te[:,dim]; pred=m_adj.predict(np.hstack([tp_te,resp_te])).clip(0,1); resid=yte-pred\n",
    "    else:\n",
    "        coefs=c_u; nz=nz_u; dim=nz[np.argsort(np.abs(coefs[nz]))[::-1][rank]]\n",
    "        proj=resp_te[:,dim]; pred=m_resp.predict(resp_te).clip(0,1); resid=yte-pred\n",
    "    df_ex=pd.DataFrame({\"dimension\":dim,\"weight\":coefs[dim],\"projection\":proj,\"prediction\":pred,\"residual\":resid,\"grade\":yte,\"teacher_id\":test.teacher_id.values,\"problem_body\":test.problem_body.values,\"answer_text\":test.answer_text.values}).drop_duplicates(subset=[\"answer_text\"])\n",
    "    lo=df_ex.nsmallest(k,\"projection\"); hi=df_ex.nlargest(k,\"projection\")\n",
    "    print(f\"=== [{mode}] Dimension {dim} weight={coefs[dim]:+.6f} ===\\n-- Low --\")\n",
    "    for _,r in lo.iterrows():\n",
    "        print(f\"Teacher:{r.teacher_id} Grade:{r.grade:.3f} Pred:{r.prediction:.3f} Resid:{r.residual:.3f} Proj:{r.projection:.3f}\\nProblem: {r.problem_body}\\nAnswer : {r.answer_text}\\n\")\n",
    "    print(\"-- High --\")\n",
    "    for _,r in hi.iterrows():\n",
    "        print(f\"Teacher:{r.teacher_id} Grade:{r.grade:.3f} Pred:{r.prediction:.3f} Resid:{r.residual:.3f} Proj:{r.projection:.3f}\\nProblem: {r.problem_body}\\nAnswer : {r.answer_text}\\n\")\n",
    "\n",
    "for i in range(min(20,len(nz_a))): show_dim(\"adjusted\",i,3)\n",
    "for i in range(min(20,len(nz_u))): show_dim(\"unadjusted\",i,3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
